<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>sparklyr: R + Spark</title>
    <meta charset="utf-8" />
    <meta name="author" content="曾意儒 Yi-Ju Tseng" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# sparklyr: R + Spark
### 曾意儒 Yi-Ju Tseng
### Chung Gung University
### 2020/06/16

---

class: inverse, center, middle

[yjtseng.info/course/spark](https://yjtseng.info/course/spark)

---
class: inverse, center, middle
# Reviews
---

## Spark

[Spark](https://spark.apache.org/) : Analytics engine for large-scale data processing

&lt;img src="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/Picture6-2.png" height="400px" style="display: block; margin: auto;" /&gt;

[Source](https://www.edureka.co/blog/spark-architecture/)

---
## dplyr

[dplyr](https://dplyr.tidyverse.org/) : Grammar of data manipulation

&lt;img src="https://miro.medium.com/max/3680/1*NXRsFH_12sfj79W-P4qI0Q.png" height="400px" style="display: block; margin: auto;" /&gt;

[Source](https://towardsdatascience.com/data-manipulation-in-r-with-dplyr-3095e0867f75)

---
## Demo on AWS

AWS: [Amazon web services](https://aws.amazon.com/tw/), education plan available

&lt;img src="https://spark.rstudio.com/examples/stand-alone-aws/images/deployment/amazon-ec2/spark-sa-setup.png" height="400px" style="display: block; margin: auto;" /&gt;

[Source](https://spark.rstudio.com/examples/stand-alone-aws/)

---
## Environment setting

1. Lunch AWS EC Instance (EC2) x1, Ubuntu / t2.medium / 20GB +
2. Open some ports (For Spark, RStudio, and the others)
3. Install Java
4. Install Spark
5. Create AMI and launch 3 EC2 instances with it
6. Install R
7. Install RStudio Server and add RStudio user
8. Install packages
9. Start the master node and worker nodes

Set your own environment [Spark Standalone Deployment in AWS](https://spark.rstudio.com/examples/stand-alone-aws/)


---
class: inverse, center, middle
## Connect to RStudio on AWS

http://ec2-18-206-187-19.compute-1.amazonaws.com:8787/

---
## Run R on Spark

- Install


```r
*install.packages("sparklyr")
library(sparklyr)
```

--


- Use


```r
install.packages("sparklyr")  
*library(sparklyr)
```



---
## Spark Config


```r
conf &lt;- spark_config()
conf$spark.executor.memory &lt;- "2GB"
conf$spark.memory.fraction &lt;- 0.9
```


---
## Spark Config


```r
sc &lt;- spark_connect(
* master="spark://ip-172-31-53-198.ec2.internal:7077",
  version = "2.1.0",
  config = conf,
  spark_home = "/home/ubuntu/spark-2.1.0-bin-hadoop2.7/")
```

---
class: inverse, center, middle
# Data Manipulation

---
## Run R on Spark - data manipulation

Copy data to Spark


```r
library(dplyr)
library(nycflights13)
library(ggplot2)
flights_spark &lt;- copy_to(sc, flights, "flights")
airlines_spark &lt;- copy_to(sc, airlines, "airlines")
src_tbls(sc)
```

```
## [1] "airlines" "flights"
```

---
## Run R on Spark - data manipulation

select()


```r
select(flights_spark, year:day, arr_delay, dep_delay)
```

```
## # Source: spark&lt;?&gt; [?? x 5]
##     year month   day arr_delay dep_delay
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1  2013     1     1        11         2
##  2  2013     1     1        20         4
##  3  2013     1     1        33         2
##  4  2013     1     1       -18        -1
##  5  2013     1     1       -25        -6
##  6  2013     1     1        12        -4
##  7  2013     1     1        19        -5
##  8  2013     1     1       -14        -3
##  9  2013     1     1        -8        -3
## 10  2013     1     1         8        -2
## # … with more rows
```

---
## Run R on Spark - data manipulation

filter()


```r
filter(flights_spark, dep_delay &gt; 1000)
```

```
## # Source: spark&lt;?&gt; [?? x 19]
##    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;
## 1  2013     1     9      641            900      1301     1242           1530
## 2  2013     1    10     1121           1635      1126     1239           1810
## 3  2013     6    15     1432           1935      1137     1607           2120
## 4  2013     7    22      845           1600      1005     1044           1815
## 5  2013     9    20     1139           1845      1014     1457           2210
## # … with 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,
## #   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,
## #   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;
```

---
## Run R on Spark - data manipulation

arrange()


```r
arrange(flights_spark, desc(dep_delay))
```

```
## # Source:     spark&lt;?&gt; [?? x 19]
## # Ordered by: desc(dep_delay)
##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;
##  1  2013     1     9      641            900      1301     1242           1530
##  2  2013     6    15     1432           1935      1137     1607           2120
##  3  2013     1    10     1121           1635      1126     1239           1810
##  4  2013     9    20     1139           1845      1014     1457           2210
##  5  2013     7    22      845           1600      1005     1044           1815
##  6  2013     4    10     1100           1900       960     1342           2211
##  7  2013     3    17     2321            810       911      135           1020
##  8  2013     6    27      959           1900       899     1236           2226
##  9  2013     7    22     2257            759       898      121           1026
## 10  2013    12     5      756           1700       896     1058           2020
## # … with more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,
## #   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,
## #   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;
```

---
## w/ Spark vs. w/o Spark


```r
system.time(flights_spark %&gt;% 
              filter(dep_delay==10))
```

```
##    user  system elapsed 
##   0.000   0.000   0.001
```


```r
system.time(flights %&gt;% 
              filter(dep_delay==10))
```

```
##    user  system elapsed 
##   0.008   0.000   0.011
```

---
class: inverse, center, middle
# Machine Learning

---
## Run R on Spark - machine learning

Copy data to spark


```r
iris_spark &lt;- 
  copy_to(sc, iris, "iris")
iris_spark
```

```
## # Source: spark&lt;iris&gt; [?? x 5]
##    Sepal_Length Sepal_Width Petal_Length Petal_Width Species
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
##  1          5.1         3.5          1.4         0.2 setosa 
##  2          4.9         3            1.4         0.2 setosa 
##  3          4.7         3.2          1.3         0.2 setosa 
##  4          4.6         3.1          1.5         0.2 setosa 
##  5          5           3.6          1.4         0.2 setosa 
##  6          5.4         3.9          1.7         0.4 setosa 
##  7          4.6         3.4          1.4         0.3 setosa 
##  8          5           3.4          1.5         0.2 setosa 
##  9          4.4         2.9          1.4         0.2 setosa 
## 10          4.9         3.1          1.5         0.1 setosa 
## # … with more rows
```


---
## Run R on Spark - machine learning

Train random forest model


```r
rf_model &lt;- iris_spark %&gt;%
  ml_random_forest(Species ~ Petal_Length + Petal_Width, 
                   type = "classification")
```

---
## Run R on Spark - machine learning

Use random forest model to predict species


```r
rf_predict &lt;- 
  ml_predict(rf_model, iris_spark) %&gt;%
  ft_string_indexer("Species", "Species_idx") %&gt;%
  collect
```

---
## Run R on Spark - machine learning

Check the prediction results


```r
table(rf_predict$Species_idx, 
      rf_predict$prediction)
```

```
##    
##      0  1  2
##   0 49  1  0
##   1  0 50  0
##   2  0  0 50
```

---
## Links for Demo

- [RStudio Server on AWS](http://ec2-18-206-187-19.compute-1.amazonaws.com:8787/)
- [Spark master UI](http://ec2-34-204-171-94.compute-1.amazonaws.com:8080/)

---
## Reference

- [sparklyr](https://spark.rstudio.com/)
- [Spark](https://spark.apache.org/)
- [AWS](https://aws.amazon.com/tw/)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
